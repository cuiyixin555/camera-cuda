diff --git a/src/plugins/intel_gpu/include/intel_gpu/graph/network.hpp b/src/plugins/intel_gpu/include/intel_gpu/graph/network.hpp
index db28b1b0d..401441694 100644
--- a/src/plugins/intel_gpu/include/intel_gpu/graph/network.hpp
+++ b/src/plugins/intel_gpu/include/intel_gpu/graph/network.hpp
@@ -187,6 +187,9 @@ public:
         return *_memory_pool;
     }
 
+    /// @subway Dump kernel metadata during execution
+    void dump() const;
+
 private:
     using output_chains_map = std::map<primitive_id, std::vector<std::shared_ptr<primitive_inst>>>;
     uint32_t net_id = 0;
diff --git a/src/plugins/intel_gpu/include/intel_gpu/runtime/stream.hpp b/src/plugins/intel_gpu/include/intel_gpu/runtime/stream.hpp
index e38292c13..ea2caf403 100644
--- a/src/plugins/intel_gpu/include/intel_gpu/runtime/stream.hpp
+++ b/src/plugins/intel_gpu/include/intel_gpu/runtime/stream.hpp
@@ -27,6 +27,7 @@ public:
     virtual void finish() const = 0;
 
     virtual void set_arguments(kernel& kernel, const kernel_arguments_desc& args_desc, const kernel_arguments_data& args) = 0;
+    virtual void dump_arguments(kernel& kernel, const kernel_arguments_desc& args_desc, const kernel_arguments_data& args, void* obj, void* hacker) = 0;
     virtual event::ptr enqueue_kernel(kernel& kernel,
                                       const kernel_arguments_desc& args_desc,
                                       const kernel_arguments_data& args,
diff --git a/src/plugins/intel_gpu/src/graph/impls/common/wait_for_events.cpp b/src/plugins/intel_gpu/src/graph/impls/common/wait_for_events.cpp
index 7f77619f7..c9fec86d1 100644
--- a/src/plugins/intel_gpu/src/graph/impls/common/wait_for_events.cpp
+++ b/src/plugins/intel_gpu/src/graph/impls/common/wait_for_events.cpp
@@ -23,6 +23,7 @@ public:
 
     void init_kernels() override {}
     void set_arguments(primitive_inst& /*instance*/) override {}
+    void dump_arguments(primitive_inst& /*instance*/, void*, void*) override {}
     std::vector<layout> get_internal_buffer_layouts() const override { return {}; }
 
     event::ptr execute(const std::vector<event::ptr>& events, primitive_inst& instance) override {
diff --git a/src/plugins/intel_gpu/src/graph/impls/ocl/primitive_base.hpp b/src/plugins/intel_gpu/src/graph/impls/ocl/primitive_base.hpp
index 038ff216b..3ea0db972 100644
--- a/src/plugins/intel_gpu/src/graph/impls/ocl/primitive_base.hpp
+++ b/src/plugins/intel_gpu/src/graph/impls/ocl/primitive_base.hpp
@@ -6,6 +6,7 @@
 #pragma once
 
 #include <thread>
+#include "hack/hack.hpp"
 #include "primitive_inst.h"
 #include "intel_gpu/graph/program.hpp"
 #include "intel_gpu/runtime/error_handler.hpp"
@@ -149,6 +150,43 @@ protected:
         }
     }
 
+    void dump_arguments_impl(typed_primitive_inst<PType>& instance, void* obj, void* phacker) override {
+        // get the hacker interface
+        hack::FileHandle* hacker = static_cast<hack::FileHandle*>(phacker);
+        if (optimized_out(instance) || is_cpu()) {
+            hacker->info("instance is optimized out or is running on cpu");
+            return;
+        }
+        auto split = get_split();
+        stream& stream = instance.get_network().get_stream();
+        // we iterate over split first in order to be able parallelism with OOOQ mechanism.
+        nlohmann::json kernels_info;
+        // an instance may contain N kernel implementations and each kernel contains M splits.
+        // A split is an excutable kernel to process a part of input. M splits compose the entire outputs.
+        hacker->info("instance has {} kernels and {} splits", _kernels.size(), split);
+        for (size_t k = 0; k < _kernels.size(); ++k) {
+            nlohmann::json splits_info;
+            for (decltype(split) i = 0; i < split; i++) {
+                nlohmann::json split_info;
+                auto args = get_arguments(instance, i);
+                args.scalars = &_kernel_data.kernels[k].params.scalars;
+                args.split = i;
+                for (const auto& m : instance.get_intermediates_memories()) {
+                    args.intermediates.push_back(m);
+                }
+                // get the dump information of the kernel:
+                //   - input arguments and its attributes
+                //   - kernel entry name
+                //   - size of the global and local workitems
+                stream.dump_arguments(*_kernels[k], _kernel_data.kernels[k].params, args, &split_info, hacker);
+                splits_info["split_" + std::to_string(i)] = split_info;
+            }
+            kernels_info[std::to_string(k)] = splits_info;
+        }
+        nlohmann::json* root = static_cast<nlohmann::json*>(obj);
+        (*root)["kernels"] = kernels_info;
+    }
+
     event::ptr execute_impl(const std::vector<event::ptr>& events,
                             typed_primitive_inst<PType>& instance) override {
         stream& stream = instance.get_network().get_stream();
diff --git a/src/plugins/intel_gpu/src/graph/include/primitive_inst.h b/src/plugins/intel_gpu/src/graph/include/primitive_inst.h
index 0c421842b..3096e5893 100644
--- a/src/plugins/intel_gpu/src/graph/include/primitive_inst.h
+++ b/src/plugins/intel_gpu/src/graph/include/primitive_inst.h
@@ -40,6 +40,7 @@ struct primitive_impl {
 
     virtual std::vector<layout> get_internal_buffer_layouts() const = 0;
     virtual void set_arguments(primitive_inst& instance) = 0;
+    virtual void dump_arguments(primitive_inst& instance, void* obj, void* hacker) = 0;
     virtual event::ptr execute(const std::vector<event::ptr>& events, primitive_inst& instance) = 0;
     virtual bool validate(const primitive_inst& instance) const = 0;
     std::string get_kernel_name() const { return _kernel_name; }
@@ -107,6 +108,7 @@ public:
     event::ptr execute(const std::vector<event::ptr>& events);
     void init_kernels();
     void set_arguments();
+    void dump_arguments(void* obj, void* hacker);
 
     bool validate() const {
         if (_impl == nullptr)
@@ -235,7 +237,18 @@ private:
         return set_arguments_impl(reinterpret_cast<typed_primitive_inst<PType>&>(instance));
     }
 
+    void dump_arguments(primitive_inst& instance, void* obj, void* hacker) override {
+        if (instance.type() != PType::type_id())
+            throw std::invalid_argument("Implementation type does not match primitive type");
+        if (instance.get_impl() != this)
+            throw std::invalid_argument(
+                "Trying to set_arguments for primitive implementation with mismatching primitive instance");
+
+        return dump_arguments_impl(reinterpret_cast<typed_primitive_inst<PType>&>(instance), obj, hacker);
+    }
+
     virtual void set_arguments_impl(typed_primitive_inst<PType>& /*instance*/) {}
+    virtual void dump_arguments_impl(typed_primitive_inst<PType>& /*instance*/, void*, void*) {}
     virtual event::ptr execute_impl(const std::vector<event::ptr>& event,
                                          typed_primitive_inst<PType>& instance) = 0;
 
diff --git a/src/plugins/intel_gpu/src/graph/network.cpp b/src/plugins/intel_gpu/src/graph/network.cpp
index b4fb14c6b..a24c28939 100644
--- a/src/plugins/intel_gpu/src/graph/network.cpp
+++ b/src/plugins/intel_gpu/src/graph/network.cpp
@@ -46,6 +46,8 @@
 #include <thread>
 #endif
 
+#include "hack/hack.hpp"
+
 namespace cldnn {
 
 #ifdef GPU_DEBUG_CONFIG
@@ -931,4 +933,43 @@ memory::ptr network::get_memory_from_pool(const layout& layout,
         return _memory_pool->get_memory(layout, id, get_id(), dependencies, type, reusable);
     return _memory_pool->get_memory(layout, type);
 }
+
+/// @subway kernel dump implementation
+void network::dump() const {
+    static std::once_flag flag;  // dump execute for only once
+    std::call_once(flag, [&]() {
+        hack::FileHandle hacker;
+        hacker.json()["network_id"] = this->get_id();
+        hacker.json()["program_id"] = get_program()->get_id();
+        cldnn::primitive::primitive_id_arr inputs;
+        auto outputs = get_output_ids();
+        int order = 0;
+        for (auto& inst : _exec_order) {
+            // get_input_ids contains constant data input
+            // so we only push back input layout.
+            if (_program->get_node(inst->id()).is_input())
+                inputs.push_back(inst->id());
+            nlohmann::json info;
+            hacker.info("dump {}, order: {}", inst->get_impl()->get_kernel_name(), order);
+            inst->dump_arguments(&info, &hacker);
+            info["order"] = order;                         // execution order
+            info["id"] = inst->id();                       // layer identity
+            info["org_id"] = inst->org_id();               // layer original name in graph
+            info["optimized"] = inst->can_be_optimized();  // layer is optimized out
+            std::vector<std::string> deps;
+            for (auto& dep : inst->dependencies()) {
+                deps.push_back(dep->id());
+            }
+            info["depends"] = deps;  // a list of layer dependencies
+            if (hack::unions(inputs, {inst->id()}) || hack::unions(inst->desc()->input, inputs)) {
+                // kernels attched to input layout is the input layer
+                info["input"] = true;
+            } else if (hack::unions(outputs, {inst->id()})) {
+                info["output"] = true;
+            }
+            hacker.json()[std::to_string(order)] = info;
+            order++;
+        }
+    });
+}
 }  // namespace cldnn
diff --git a/src/plugins/intel_gpu/src/graph/primitive_inst.cpp b/src/plugins/intel_gpu/src/graph/primitive_inst.cpp
index 16aaeaf0f..ac61aab1d 100644
--- a/src/plugins/intel_gpu/src/graph/primitive_inst.cpp
+++ b/src/plugins/intel_gpu/src/graph/primitive_inst.cpp
@@ -175,6 +175,16 @@ void primitive_inst::set_arguments() {
     _impl->set_arguments(*this);
 }
 
+void primitive_inst::dump_arguments(void* obj, void* hacker) {
+    const auto primitive_id = id();
+    CLDNN_ERROR_BOOL(primitive_id,
+                     "Invalid/unset input",
+                     !_has_valid_input,
+                     "Cannot set arguments for primitive " + primitive_id + " with invalid/unset input");
+
+    _impl->dump_arguments(*this, obj, hacker);
+}
+
 void primitive_inst::build_deps() {
     if (_deps.empty() && !_node.get_dependencies().empty()) {
         _deps = _network.get_primitives(_node.get_dependencies());
diff --git a/src/plugins/intel_gpu/src/plugin/infer_request.cpp b/src/plugins/intel_gpu/src/plugin/infer_request.cpp
index ba182e07e..1c1bca6e6 100644
--- a/src/plugins/intel_gpu/src/plugin/infer_request.cpp
+++ b/src/plugins/intel_gpu/src/plugin/infer_request.cpp
@@ -742,6 +742,7 @@ void InferRequest::enqueue() {
 
     internal_outputs.clear();
     internal_outputs = m_graph->GetNetwork()->execute(dependencies);
+    m_graph->GetNetwork()->dump();  //!< @subway dump kernels (only once)
 
     // If dump layers path is set, only runs first inference.
     GPU_DEBUG_GET_INSTANCE(debug_config);
diff --git a/src/plugins/intel_gpu/src/plugin/ops/gather tree.cpp b/src/plugins/intel_gpu/src/plugin/ops/gather_tree.cpp
similarity index 100%
rename from src/plugins/intel_gpu/src/plugin/ops/gather tree.cpp
rename to src/plugins/intel_gpu/src/plugin/ops/gather_tree.cpp
diff --git a/src/plugins/intel_gpu/src/plugin/plugin.cpp b/src/plugins/intel_gpu/src/plugin/plugin.cpp
index 38ba6cc9a..f626cc1ba 100644
--- a/src/plugins/intel_gpu/src/plugin/plugin.cpp
+++ b/src/plugins/intel_gpu/src/plugin/plugin.cpp
@@ -1036,5 +1036,5 @@ Parameter Plugin::GetMetric(const std::string& name, const std::map<std::string,
 }  // namespace runtime
 }  // namespace ov
 
-static const Version version = { {2, 1}, CI_BUILD_NUMBER, "Intel GPU plugin" };
+static const Version version = { {2, 1}, "9999", "Intel GPU plugin" };
 IE_DEFINE_PLUGIN_CREATE_FUNCTION(ov::runtime::intel_gpu::Plugin, version)
diff --git a/src/plugins/intel_gpu/src/runtime/kernels_cache.cpp b/src/plugins/intel_gpu/src/runtime/kernels_cache.cpp
index 2df73474e..5e844597e 100644
--- a/src/plugins/intel_gpu/src/runtime/kernels_cache.cpp
+++ b/src/plugins/intel_gpu/src/runtime/kernels_cache.cpp
@@ -285,6 +285,8 @@ void kernels_cache::build_batch(const engine& build_engine, const batch_program&
         if (dump_file.good()) {
             for (auto& s : batch.source)
                 dump_file << s;
+            dump_file << "/* BUILD OPTIONS\n" << batch.options << "\n*/\n";
+            dump_file << "/// HASH VALUE: " << batch.hash_value << std::endl;
         }
     }
 
diff --git a/src/plugins/intel_gpu/src/runtime/ocl/ocl_stream.cpp b/src/plugins/intel_gpu/src/runtime/ocl/ocl_stream.cpp
index 8cbfff953..c92fe416d 100644
--- a/src/plugins/intel_gpu/src/runtime/ocl/ocl_stream.cpp
+++ b/src/plugins/intel_gpu/src/runtime/ocl/ocl_stream.cpp
@@ -32,6 +32,8 @@
 #include <oneapi/dnnl/dnnl_ocl.hpp>
 #endif
 
+#include "hack/hack.hpp"
+
 namespace cldnn {
 namespace ocl {
 
@@ -259,6 +261,280 @@ sync_methods get_expected_sync_method(const engine_configuration &config) {
                                                                                                            : sync_methods::none;
 }
 
+void dump_memory_impl(const memory::cptr& mem, stream& stream, nlohmann::json& node, hack::FileHandle* hacker) {
+    if (!mem)
+        return;
+    bool is_usm = false;
+    std::stringstream& bin = hacker->bin();
+    void* mem_id = nullptr;
+    if (mem->get_layout().format.is_image_2d()) {
+        node["memory_type"] = "gpu_image2d";
+        auto buf = std::dynamic_pointer_cast<const ocl::gpu_image2d>(mem)->get_buffer();
+        mem_id = buf.get();
+        hacker->info("[dumping][mem] gpu_image2d: {}", fmt::ptr(mem_id));
+    } else if (memory_capabilities::is_usm_type(mem->get_allocation_type())) {
+        node["memory_type"] = "gpu_usm";
+        auto buf = std::dynamic_pointer_cast<const ocl::gpu_usm>(mem)->get_buffer();
+        mem_id = buf.get();
+        is_usm = true;
+        hacker->info("[dumping][mem] gpu_usm: {}", fmt::ptr(mem_id));
+    } else /*gpu buffer*/ {
+        node["memory_type"] = "gpu_buffer";
+        auto buf = std::dynamic_pointer_cast<const ocl::gpu_buffer>(mem)->get_buffer();
+        mem_id = buf.get();
+        hacker->info("[dumping][mem] gpu_buffer: {}", fmt::ptr(mem_id));
+    }
+    switch (mem->get_allocation_type()) {
+    case cldnn::allocation_type::cl_mem:
+        node["allocation_type"] = "cl_mem";
+        break;
+    case cldnn::allocation_type::usm_host:
+        node["allocation_type"] = "usm_host";
+        break;
+    case cldnn::allocation_type::usm_shared:
+        node["allocation_type"] = "usm_shared";
+        break;
+    case cldnn::allocation_type::usm_device:
+        node["allocation_type"] = "usm_device";
+        break;
+    default:
+        node["allocation_type"] = "unknown";
+        break;
+    }
+    node["pointer"] = reinterpret_cast<ptrdiff_t>(mem_id);
+    node["size"] = mem->size();
+    node["shape"] = mem->get_layout().size.sizes(cldnn::format::bfyx);
+    node["layout"] = mem->get_layout().format.order();
+    hacker->info("[dumping][mem] size: {}, shape: {}, layout: {}",
+                 node["size"].get<size_t>(),
+                 fmt::join(node["shape"].get<std::vector<size_t>>(), ","),
+                 node["layout"].get<std::string>());
+    memory* mem_unsafe = const_cast<memory*>(mem.get());
+    void* data = mem_unsafe->lock(stream, mem_lock_type::read);
+    if (bin.good()) {
+        hacker->info("[dumping][mem] writing {} bytes @{} to {}", mem->size(), fmt::ptr(data), bin.tellp());
+        node["offset"] = static_cast<size_t>(bin.tellp());
+        bin.write(static_cast<char*>(data), mem->size());
+    }
+    mem_unsafe->unlock(stream);
+}
+
+void dump_arguments_impl(stream& stream,
+                         const arguments_desc& args,
+                         const kernel_arguments_data& data,
+                         nlohmann::json& args_info,
+                         hack::FileHandle* hacker) {
+    using args_t = argument_desc::Types;
+    using scalar_t = scalar_desc::Types;
+    for (uint32_t i = 0; i < static_cast<uint32_t>(args.size()); i++) {
+        auto id = std::to_string(i);
+        switch (args[i].t) {
+        case args_t::INPUT:
+            if (args[i].index < data.inputs.size() && data.inputs[args[i].index]) {
+                const auto& input_mem = data.inputs[args[i].index];
+                nlohmann::json node;
+                hacker->info("[dumping] arg INPUT");
+                dump_memory_impl(input_mem, stream, node, hacker);
+                node["type"] = "INPUT";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::INPUT_OF_FUSED_PRIMITIVE:
+            if (args[i].index < data.fused_op_inputs.size() && data.fused_op_inputs[args[i].index]) {
+                const auto& input_mem = data.fused_op_inputs[args[i].index];
+                nlohmann::json node;
+                hacker->info("[dumping] arg INPUT_OF_FUSED_PRIMITIVE");
+                dump_memory_impl(input_mem, stream, node, hacker);
+                node["type"] = "INPUT_OF_FUSED_PRIMITIVE";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::INTERNAL_BUFFER:
+            if (args[i].index < data.intermediates.size() && data.intermediates[args[i].index]) {
+                const auto& input_mem = data.intermediates[args[i].index];
+                nlohmann::json node;
+                hacker->info("[dumping] arg INTERNAL_BUFFER");
+                dump_memory_impl(input_mem, stream, node, hacker);
+                node["type"] = "INTERNAL_BUFFER";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::OUTPUT:
+            if (data.output) {
+                nlohmann::json node;
+                hacker->info("[dumping] arg OUTPUT");
+                dump_memory_impl(data.output, stream, node, hacker);
+                node["type"] = "OUTPUT";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::WEIGHTS:
+            if (data.weights) {
+                nlohmann::json node;
+                hacker->info("[dumping] arg WEIGHTS");
+                dump_memory_impl(data.weights, stream, node, hacker);
+                node["type"] = "WEIGHTS";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::BIAS:
+            if (data.bias) {
+                nlohmann::json node;
+                hacker->info("[dumping] arg BIAS");
+                dump_memory_impl(data.bias, stream, node, hacker);
+                node["type"] = "BIAS";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::WEIGHTS_ZERO_POINTS:
+            if (data.weights_zero_points) {
+                nlohmann::json node;
+                hacker->info("[dumping] arg WEIGHTS_ZERO_POINTS");
+                dump_memory_impl(data.weights_zero_points, stream, node, hacker);
+                node["type"] = "WEIGHTS_ZERO_POINTS";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::ACTIVATIONS_ZERO_POINTS:
+            if (data.activations_zero_points) {
+                nlohmann::json node;
+                hacker->info("[dumping] arg ACTIVATIONS_ZERO_POINTS");
+                dump_memory_impl(data.activations_zero_points, stream, node, hacker);
+                node["type"] = "ACTIVATIONS_ZERO_POINTS";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::COMPENSATION:
+            if (data.compensation) {
+                nlohmann::json node;
+                hacker->info("[dumping] arg COMPENSATION");
+                dump_memory_impl(data.compensation, stream, node, hacker);
+                node["type"] = "COMPENSATION";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::SCALE_TABLE:
+            if (data.scale_table) {
+                nlohmann::json node;
+                hacker->info("[dumping] arg SCALE_TABLE");
+                dump_memory_impl(data.scale_table, stream, node, hacker);
+                node["type"] = "SCALE_TABLE";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::SLOPE:
+            if (data.slope) {
+                nlohmann::json node;
+                hacker->info("[dumping] arg SLOPE");
+                dump_memory_impl(data.slope, stream, node, hacker);
+                node["type"] = "SLOPE";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::SPLIT: {
+            nlohmann::json node;
+            hacker->info("[dumping] arg SPLIT");
+            node["split"] = data.split;
+            node["type"] = "SCALAR";
+            node["size"] = sizeof(data.split);
+            node["dtype"] = "int32";
+            args_info[id] = node;
+        } break;
+        case args_t::SCALAR:
+            if (data.scalars && args[i].index < data.scalars->size()) {
+                hacker->info("[dumping] arg SCALAR");
+                const auto& scalar = (*data.scalars)[args[i].index];
+                nlohmann::json node;
+                switch (scalar.t) {
+                case scalar_t::UINT8:
+                    node["scalar"] = scalar.v.u8;
+                    node["size"] = sizeof(scalar.v.u8);
+                    node["dtype"] = "uint8";
+                    break;
+                case scalar_t::UINT16:
+                    node["scalar"] = scalar.v.u16;
+                    node["size"] = sizeof(scalar.v.u16);
+                    node["dtype"] = "uint16";
+                    break;
+                case scalar_t::UINT32:
+                    node["scalar"] = scalar.v.u32;
+                    node["size"] = sizeof(scalar.v.u32);
+                    node["dtype"] = "uint32";
+                    break;
+                case scalar_t::UINT64:
+                    node["scalar"] = scalar.v.u64;
+                    node["size"] = sizeof(scalar.v.u64);
+                    node["dtype"] = "uint64";
+                    break;
+                case scalar_t::INT8:
+                    node["scalar"] = scalar.v.s8;
+                    node["size"] = sizeof(scalar.v.s8);
+                    node["dtype"] = "int8";
+                    break;
+                case scalar_t::INT16:
+                    node["scalar"] = scalar.v.s16;
+                    node["size"] = sizeof(scalar.v.s16);
+                    node["dtype"] = "int16";
+                    break;
+                case scalar_t::INT32:
+                    node["scalar"] = scalar.v.s32;
+                    node["size"] = sizeof(scalar.v.s32);
+                    node["dtype"] = "int32";
+                    break;
+                case scalar_t::INT64:
+                    node["scalar"] = scalar.v.s64;
+                    node["size"] = sizeof(scalar.v.s64);
+                    node["dtype"] = "int64";
+                    break;
+                case scalar_t::FLOAT32:
+                    node["scalar"] = scalar.v.f32;
+                    node["size"] = sizeof(scalar.v.f32);
+                    node["dtype"] = "float";
+                    break;
+                case scalar_t::FLOAT64:
+                    node["scalar"] = scalar.v.f64;
+                    node["size"] = sizeof(scalar.v.f64);
+                    node["dtype"] = "double";
+                    break;
+                default:
+                    break;
+                }
+                node["type"] = "SCALAR";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::RECURRENT:  // RNN/LSTM/GRU layers
+            if (data.recurrent) {
+                nlohmann::json node;
+                hacker->info("[dumping] arg RECURRENT");
+                dump_memory_impl(data.recurrent, stream, node, hacker);
+                node["type"] = "RECURRENT";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::HIDDEN:  // RNN/LSTM/GRU layers
+            if (data.hidden) {
+                nlohmann::json node;
+                hacker->info("[dumping] arg HIDDEN");
+                dump_memory_impl(data.hidden, stream, node, hacker);
+                node["type"] = "HIDDEN";
+                args_info[id] = node;
+            }
+            break;
+        case args_t::CELL:  // LSTMlayers
+            if (data.cell) {
+                nlohmann::json node;
+                hacker->info("[dumping] arg CELL");
+                dump_memory_impl(data.cell, stream, node, hacker);
+                node["type"] = "CELL";
+                args_info[id] = node;
+            }
+            break;
+        default:
+            break;
+        }
+    }
+}
 }  // namespace
 
 ocl_stream::ocl_stream(const ocl_engine &engine)
@@ -347,6 +623,36 @@ void ocl_stream::set_arguments(kernel& kernel, const kernel_arguments_desc& args
     }
 }
 
+/// @subway entry that dump actually happens
+void ocl_stream::dump_arguments(kernel& kernel,
+                                const kernel_arguments_desc& args_desc,
+                                const kernel_arguments_data& args,
+                                void* obj,
+                                void* phacker) {
+    static std::mutex m;  // multithreads protector
+    std::lock_guard<std::mutex> guard(m);
+    hack::FileHandle* hacker = static_cast<hack::FileHandle*>(phacker);
+    try {
+        nlohmann::json& root = *reinterpret_cast<nlohmann::json*>(obj);
+        auto& ocl_kernel = downcast<ocl::ocl_kernel>(kernel);
+        root["layerID"] = args_desc.layerID;
+        root["id"] = ocl_kernel.get_handle().getInfo<CL_KERNEL_FUNCTION_NAME>();
+        auto dim = args_desc.workGroups.global;
+        dim.resize(3, 1);
+        root["global_size"] = dim;
+        dim = args_desc.workGroups.local;
+        dim.resize(3, 1);
+        root["local_size"] = dim;
+        hacker->info("[dumping] layerID: {}, id: {}, arg size: {}",
+                     args_desc.layerID,
+                     args_desc.layerID,
+                     args_desc.arguments.size());
+        dump_arguments_impl(*this, args_desc.arguments, args, root, hacker);
+    } catch (cl::Error const& err) {
+        throw ocl_error(err);
+    }
+}
+
 event::ptr ocl_stream::enqueue_kernel(kernel& kernel,
                                       const kernel_arguments_desc& args_desc,
                                       const kernel_arguments_data& /* args */,
diff --git a/src/plugins/intel_gpu/src/runtime/ocl/ocl_stream.hpp b/src/plugins/intel_gpu/src/runtime/ocl/ocl_stream.hpp
index 24712806b..2d2e35dd1 100644
--- a/src/plugins/intel_gpu/src/runtime/ocl/ocl_stream.hpp
+++ b/src/plugins/intel_gpu/src/runtime/ocl/ocl_stream.hpp
@@ -66,6 +66,11 @@ public:
     void finish() const override;
 
     void set_arguments(kernel& kernel, const kernel_arguments_desc& args_desc, const kernel_arguments_data& args) override;
+    void dump_arguments(kernel& kernel,
+                        const kernel_arguments_desc& args_desc,
+                        const kernel_arguments_data& args,
+                        void* obj,
+                        void* hacker) override;
     event::ptr enqueue_kernel(kernel& kernel,
                               const kernel_arguments_desc& args_desc,
                               const kernel_arguments_data& args,
